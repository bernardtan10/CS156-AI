{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <b>CS156 (Introduction to AI), Spring 2022</b>\n",
        "# <u><b>Homework 11 submission</b></u>"
      ],
      "metadata": {
        "id": "1ayfL9PsIAvW"
      },
      "id": "1ayfL9PsIAvW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Roster Name: Bernard Tan\n",
        "### Preferred Name (if different): Bernard\n",
        "### Student ID: 015215317\n",
        "### Email address: bernard.tan@sjsu.edu\n",
        "Any special notes or anything you would like to communicate to me about this homework submission goes in here."
      ],
      "metadata": {
        "id": "hxlweu01IJP2"
      },
      "id": "hxlweu01IJP2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  <u>References and sources </u>"
      ],
      "metadata": {
        "id": "Xbj7VYSNINOk"
      },
      "id": "Xbj7VYSNINOk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "List all your references and sources here.\n",
        "This includes all sites/discussion boards/blogs/posts/etc. where you grabbed some code examples."
      ],
      "metadata": {
        "id": "dGUWpvRvIPbk"
      },
      "id": "dGUWpvRvIPbk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  <u>Solution</u>"
      ],
      "metadata": {
        "id": "3KZi36WNIQOL"
      },
      "id": "3KZi36WNIQOL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load libraries and set random number generator seed"
      ],
      "metadata": {
        "id": "6Iwpp-bnIUjM"
      },
      "id": "6Iwpp-bnIUjM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5604150-84a8-491a-a7e8-76ad47edc1ff",
      "metadata": {
        "id": "f5604150-84a8-491a-a7e8-76ad47edc1ff"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da56b39d-afbf-40f8-bf6d-621b03032c50",
      "metadata": {
        "id": "da56b39d-afbf-40f8-bf6d-621b03032c50"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6ffe3ac1-8b2e-4d18-a9aa-437e432aa6b4",
      "metadata": {
        "id": "6ffe3ac1-8b2e-4d18-a9aa-437e432aa6b4"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"FrozenLake-v0\", is_slippery=False).env "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "149ad399-257a-41e8-8970-4019dcfabbba",
      "metadata": {
        "id": "149ad399-257a-41e8-8970-4019dcfabbba",
        "outputId": "9244cc65-27b5-4e80-d238-eaa3753e37b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action Space Discrete(4)\n",
            "State Space Discrete(16)\n"
          ]
        }
      ],
      "source": [
        "env.seed(42)\n",
        "env.reset()\n",
        "env.render()\n",
        "\n",
        "print(\"Action Space {}\".format(env.action_space))\n",
        "print(\"State Space {}\".format(env.observation_space))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "67290aa0-0710-4595-bf3c-0476c8f2ed0b",
      "metadata": {
        "id": "67290aa0-0710-4595-bf3c-0476c8f2ed0b",
        "outputId": "4c709d11-77d0-4209-9e29-43ed4f3d62fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 50 Total Reward: 0.0\n",
            "Episode 100 Total Reward: 0.0\n",
            "Episode 150 Total Reward: 0.0\n",
            "Episode 200 Total Reward: 0.0\n",
            "Episode 250 Total Reward: 0.0\n",
            "Episode 300 Total Reward: 0.0\n",
            "Episode 350 Total Reward: 0.0\n",
            "Episode 400 Total Reward: 0.0\n",
            "Episode 450 Total Reward: 0.0\n",
            "Episode 500 Total Reward: 0.0\n",
            "Episode 550 Total Reward: 0.0\n",
            "Episode 600 Total Reward: 0.0\n",
            "Episode 650 Total Reward: 0.0\n",
            "Episode 700 Total Reward: 0.0\n",
            "Episode 750 Total Reward: 0.0\n",
            "Episode 800 Total Reward: 0.0\n",
            "Episode 850 Total Reward: 0.0\n",
            "Episode 900 Total Reward: 0.0\n",
            "Episode 950 Total Reward: 0.0\n",
            "Episode 1000 Total Reward: 0.0\n",
            "Episode 1050 Total Reward: 0.0\n",
            "Episode 1100 Total Reward: 0.0\n",
            "Episode 1150 Total Reward: 0.0\n",
            "Episode 1200 Total Reward: 0.0\n",
            "Episode 1250 Total Reward: 0.0\n",
            "Episode 1300 Total Reward: 0.0\n",
            "Episode 1350 Total Reward: 0.0\n",
            "Episode 1400 Total Reward: 0.0\n",
            "Episode 1450 Total Reward: 0.0\n",
            "Episode 1500 Total Reward: 0.0\n",
            "Episode 1550 Total Reward: 0.0\n",
            "Episode 1600 Total Reward: 0.0\n",
            "Episode 1650 Total Reward: 0.0\n",
            "Episode 1700 Total Reward: 0.0\n",
            "Episode 1750 Total Reward: 0.0\n",
            "Episode 1800 Total Reward: 0.0\n",
            "Episode 1850 Total Reward: 0.0\n",
            "Episode 1900 Total Reward: 0.0\n",
            "Episode 1950 Total Reward: 0.0\n",
            "Episode 2000 Total Reward: 0.0\n",
            "Episode 2050 Total Reward: 0.0\n",
            "Episode 2100 Total Reward: 0.0\n",
            "Episode 2150 Total Reward: 0.0\n",
            "Episode 2200 Total Reward: 0.0\n",
            "Episode 2250 Total Reward: 0.0\n",
            "Episode 2300 Total Reward: 0.0\n",
            "Episode 2350 Total Reward: 0.0\n",
            "Episode 2400 Total Reward: 0.0\n",
            "Episode 2450 Total Reward: 0.0\n",
            "Episode 2500 Total Reward: 0.0\n",
            "Episode 2550 Total Reward: 0.0\n",
            "Episode 2600 Total Reward: 0.0\n",
            "Episode 2650 Total Reward: 0.0\n",
            "Episode 2700 Total Reward: 0.0\n",
            "Episode 2750 Total Reward: 0.0\n",
            "Episode 2800 Total Reward: 0.0\n",
            "Episode 2850 Total Reward: 0.0\n",
            "Episode 2900 Total Reward: 0.0\n",
            "Episode 2950 Total Reward: 0.0\n",
            "Episode 3000 Total Reward: 0.0\n",
            "Episode 3050 Total Reward: 0.0\n",
            "Episode 3100 Total Reward: 0.0\n",
            "Episode 3150 Total Reward: 0.0\n",
            "Episode 3200 Total Reward: 0.0\n",
            "Episode 3250 Total Reward: 0.0\n",
            "Episode 3300 Total Reward: 0.0\n",
            "Episode 3350 Total Reward: 0.0\n",
            "Episode 3400 Total Reward: 0.0\n",
            "Episode 3450 Total Reward: 0.0\n",
            "Episode 3500 Total Reward: 0.0\n",
            "Episode 3550 Total Reward: 0.0\n",
            "Episode 3600 Total Reward: 0.0\n",
            "Episode 3650 Total Reward: 0.0\n",
            "Episode 3700 Total Reward: 0.0\n",
            "Episode 3750 Total Reward: 0.0\n",
            "Episode 3800 Total Reward: 0.0\n",
            "Episode 3850 Total Reward: 0.0\n",
            "Episode 3900 Total Reward: 0.0\n",
            "Episode 3950 Total Reward: 0.0\n",
            "Episode 4000 Total Reward: 0.0\n",
            "Episode 4050 Total Reward: 0.0\n",
            "Episode 4100 Total Reward: 0.0\n",
            "Episode 4150 Total Reward: 0.0\n",
            "Episode 4200 Total Reward: 0.0\n",
            "Episode 4250 Total Reward: 0.0\n",
            "Episode 4300 Total Reward: 0.0\n",
            "Episode 4350 Total Reward: 0.0\n",
            "Episode 4400 Total Reward: 0.0\n",
            "Episode 4450 Total Reward: 0.0\n",
            "Episode 4500 Total Reward: 0.0\n",
            "Episode 4550 Total Reward: 0.0\n",
            "Episode 4600 Total Reward: 0.0\n",
            "Episode 4650 Total Reward: 0.0\n",
            "Episode 4700 Total Reward: 0.0\n",
            "Episode 4750 Total Reward: 0.0\n",
            "Episode 4800 Total Reward: 0.0\n",
            "Episode 4850 Total Reward: 0.0\n",
            "Episode 4900 Total Reward: 0.0\n",
            "Episode 4950 Total Reward: 0.0\n",
            "Episode 5000 Total Reward: 0.0\n",
            "Episode 5050 Total Reward: 0.0\n",
            "Episode 5100 Total Reward: 0.0\n",
            "Episode 5150 Total Reward: 0.0\n",
            "Episode 5200 Total Reward: 0.0\n",
            "Episode 5250 Total Reward: 0.0\n",
            "Episode 5300 Total Reward: 0.0\n",
            "Episode 5350 Total Reward: 0.0\n",
            "Episode 5400 Total Reward: 0.0\n",
            "Episode 5450 Total Reward: 0.0\n",
            "Episode 5500 Total Reward: 0.0\n",
            "Episode 5550 Total Reward: 0.0\n",
            "Episode 5600 Total Reward: 0.0\n",
            "Episode 5650 Total Reward: 0.0\n",
            "Episode 5700 Total Reward: 0.0\n",
            "Episode 5750 Total Reward: 0.0\n",
            "Episode 5800 Total Reward: 0.0\n",
            "Episode 5850 Total Reward: 0.0\n",
            "Episode 5900 Total Reward: 0.0\n",
            "Episode 5950 Total Reward: 0.0\n",
            "Episode 6000 Total Reward: 0.0\n",
            "Episode 6050 Total Reward: 0.0\n",
            "Episode 6100 Total Reward: 0.0\n",
            "Episode 6150 Total Reward: 0.0\n",
            "Episode 6200 Total Reward: 0.0\n",
            "Episode 6250 Total Reward: 0.0\n",
            "Episode 6300 Total Reward: 0.0\n",
            "Episode 6350 Total Reward: 0.0\n",
            "Episode 6400 Total Reward: 0.0\n",
            "Episode 6450 Total Reward: 0.0\n",
            "Episode 6500 Total Reward: 0.0\n",
            "Episode 6550 Total Reward: 0.0\n",
            "Episode 6600 Total Reward: 0.0\n",
            "Episode 6650 Total Reward: 0.0\n",
            "Episode 6700 Total Reward: 0.0\n",
            "Episode 6750 Total Reward: 0.0\n",
            "Episode 6800 Total Reward: 0.0\n",
            "Episode 6850 Total Reward: 0.0\n",
            "Episode 6900 Total Reward: 0.0\n",
            "Episode 6950 Total Reward: 0.0\n",
            "Episode 7000 Total Reward: 0.0\n",
            "Episode 7050 Total Reward: 0.0\n",
            "Episode 7100 Total Reward: 0.0\n",
            "Episode 7150 Total Reward: 0.0\n",
            "Episode 7200 Total Reward: 0.0\n",
            "Episode 7250 Total Reward: 0.0\n",
            "Episode 7300 Total Reward: 0.0\n",
            "Episode 7350 Total Reward: 0.0\n",
            "Episode 7400 Total Reward: 0.0\n",
            "Episode 7450 Total Reward: 0.0\n",
            "Episode 7500 Total Reward: 0.0\n",
            "Episode 7550 Total Reward: 0.0\n",
            "Episode 7600 Total Reward: 0.0\n",
            "Episode 7650 Total Reward: 0.0\n",
            "Episode 7700 Total Reward: 0.0\n",
            "Episode 7750 Total Reward: 0.0\n",
            "Episode 7800 Total Reward: 0.0\n",
            "Episode 7850 Total Reward: 0.0\n",
            "Episode 7900 Total Reward: 0.0\n",
            "Episode 7950 Total Reward: 0.0\n",
            "Episode 8000 Total Reward: 0.0\n",
            "Episode 8050 Total Reward: 0.0\n",
            "Episode 8100 Total Reward: 0.0\n",
            "Episode 8150 Total Reward: 0.0\n",
            "Episode 8200 Total Reward: 1.0\n",
            "Episode 8250 Total Reward: 0.0\n",
            "Episode 8300 Total Reward: 1.0\n",
            "Episode 8350 Total Reward: 1.0\n",
            "Episode 8400 Total Reward: 1.0\n",
            "Episode 8450 Total Reward: 1.0\n",
            "Episode 8500 Total Reward: 0.0\n",
            "Episode 8550 Total Reward: 1.0\n",
            "Episode 8600 Total Reward: 1.0\n",
            "Episode 8650 Total Reward: 1.0\n",
            "Episode 8700 Total Reward: 1.0\n",
            "Episode 8750 Total Reward: 1.0\n",
            "Episode 8800 Total Reward: 1.0\n",
            "Episode 8850 Total Reward: 1.0\n",
            "Episode 8900 Total Reward: 1.0\n",
            "Episode 8950 Total Reward: 1.0\n",
            "Episode 9000 Total Reward: 1.0\n",
            "Episode 9050 Total Reward: 1.0\n",
            "Episode 9100 Total Reward: 1.0\n",
            "Episode 9150 Total Reward: 1.0\n",
            "Episode 9200 Total Reward: 1.0\n",
            "Episode 9250 Total Reward: 0.0\n",
            "Episode 9300 Total Reward: 0.0\n",
            "Episode 9350 Total Reward: 1.0\n",
            "Episode 9400 Total Reward: 1.0\n",
            "Episode 9450 Total Reward: 0.0\n",
            "Episode 9500 Total Reward: 0.0\n",
            "Episode 9550 Total Reward: 0.0\n",
            "Episode 9600 Total Reward: 1.0\n",
            "Episode 9650 Total Reward: 1.0\n",
            "Episode 9700 Total Reward: 1.0\n",
            "Episode 9750 Total Reward: 1.0\n",
            "Episode 9800 Total Reward: 1.0\n",
            "Episode 9850 Total Reward: 1.0\n",
            "Episode 9900 Total Reward: 0.0\n",
            "Episode 9950 Total Reward: 1.0\n"
          ]
        }
      ],
      "source": [
        "qtable = np.zeros([env.observation_space.n, env.action_space.n]) #You could also make this dynamic if you don't know all games states upfront\n",
        "discount = 0.9 \n",
        "learningrate = 0.9 \n",
        "epsilon = 0.2 \n",
        "for episode in range(1,10000):\n",
        "    done = False\n",
        "    reward_total = 0\n",
        "    state = env.reset()\n",
        "    while done != True:\n",
        "        explore_eploit = np.random.uniform(0, 1)\n",
        "        if explore_eploit < epsilon:\n",
        "            action = env.action_space.sample() # explore action space\n",
        "        else:\n",
        "            action = np.argmax(qtable[state]) # exploit learned values\n",
        "        \n",
        "        state_new, reward, done, info = env.step(action) #take the action\n",
        "        qtable[state,action] += learningrate * (reward + discount * np.max(qtable[state_new,:]) - qtable[state,action]) #Update Q-marix using Bellman equation\n",
        "        reward_total = reward_total + reward\n",
        "        state = state_new   \n",
        "    if episode % 50 == 0:\n",
        "        print('Episode {} Total Reward: {}'.format(episode,reward_total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7188387d-52d4-487d-ad11-6da82526135e",
      "metadata": {
        "id": "7188387d-52d4-487d-ad11-6da82526135e",
        "outputId": "91e61482-624a-4ff6-f2e5-aeca408ee202",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.531441   0.59049    0.4782969  0.531441  ]\n",
            " [0.531441   0.         0.43046721 0.47829685]\n",
            " [0.4782969  0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.59049    0.6561     0.         0.531441  ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.6561     0.         0.729      0.59049   ]\n",
            " [0.6561     0.81       0.81       0.        ]\n",
            " [0.729      0.9        0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.81       0.9        0.729     ]\n",
            " [0.81       0.9        1.         0.81      ]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(qtable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d1ac0e69-f119-4efb-897e-6ac410322fa0",
      "metadata": {
        "id": "d1ac0e69-f119-4efb-897e-6ac410322fa0",
        "outputId": "6c784f05-e173-4abf-e68f-117ab59a7531",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Down)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "H\u001b[41mF\u001b[0mFG\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HF\u001b[41mF\u001b[0mG\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Total reward is 1.0\n"
          ]
        }
      ],
      "source": [
        "# Let's see how the algorithm solves the taxi game by following the policy to take actions delivering max value\n",
        "\n",
        "reward_total=0\n",
        "obs= env.reset()\n",
        "env.render()\n",
        "\n",
        "done=False\n",
        "\n",
        "while done != True: \n",
        "    action = np.argmax(qtable[obs])\n",
        "    obs, reward, done, info = env.step(action) #take step using selected action\n",
        "    reward_total = reward_total + reward\n",
        "    env.render()\n",
        "#Print the reward of these actions\n",
        "print(\"Total reward is %r\" % reward_total)  "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "CS156(Assignment11).ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}